{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display as display_dataframe\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "import keras\n",
    "# from keras.applications.xception import Xception\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.applications.vgg19 import VGG19\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.mobilenetv2 import MobileNetV2\n",
    "# from keras.applications.densenet import DenseNet121\n",
    "import cv2\n",
    "import os\n",
    "import seaborn as sns\n",
    "# from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def display_image(image, title=''):\n",
    "    cv2.imshow(title, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data of format:\n",
      "data_length(ण) = 2000\n",
      "data_length(फ) = 2000\n",
      "data_length(ज्ञ) = 2000\n",
      "data_length(द) = 2000\n",
      "data_length(ल) = 2000\n",
      "data_length(ट) = 2000\n",
      "data_length(र) = 2000\n",
      "data_length(ब) = 2000\n",
      "data_length(व) = 2000\n",
      "data_length(ङ) = 2000\n",
      "data_length(त्र) = 2000\n",
      "data_length(न) = 2000\n",
      "data_length(ष) = 2000\n",
      "data_length(ड) = 2000\n",
      "data_length(ज) = 2000\n",
      "data_length(श) = 2000\n",
      "data_length(ठ) = 2000\n",
      "data_length(त) = 2000\n",
      "data_length(थ) = 2000\n",
      "data_length(झ) = 2000\n",
      "data_length(घ) = 2000\n",
      "data_length(ख) = 2000\n",
      "data_length(ञ) = 2000\n",
      "data_length(क्ष) = 2000\n",
      "data_length(ढ) = 2000\n",
      "data_length(भ) = 2000\n",
      "data_length(छ) = 2000\n",
      "data_length(ध) = 2000\n",
      "data_length(ह) = 2000\n",
      "data_length(य) = 2000\n",
      "data_length(च) = 2000\n",
      "data_length(क) = 2000\n",
      "data_length(स) = 2000\n",
      "data_length(ग) = 2000\n",
      "data_length(म) = 2000\n",
      "data_length(प) = 2000\n"
     ]
    }
   ],
   "source": [
    "#vgg can't take input of 28x28 so we shall resize all our images\n",
    "pickle_folder = \"pickle files\"\n",
    "data = pickle.load(open('data.pickle', 'rb'))\n",
    "print(\"Data of format:\")\n",
    "for ch in data:\n",
    "    print(\"data_length(\" + ch + \") =\", len(data[ch]))\n",
    "\n",
    "#no. of classes\n",
    "classes = len(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rearranging data in input-output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpickled\n"
     ]
    }
   ],
   "source": [
    "file = \"class_numerals_{}.pickle\".format(classes)\n",
    "if file in os.listdir(pickle_folder):\n",
    "    class_numerals = pickle.load(open(os.path.join(pickle_folder, file), 'rb'))\n",
    "    print(\"Unpickled\")\n",
    "else:\n",
    "    class_numerals = {i:list(data.keys())[i] for i in range(classes)}\n",
    "    pickle.dump(class_numerals, open(os.path.join(pickle_folder, file), 'wb'))\n",
    "    print(\"Error. Incompatible. Pickled new file:\", file)\n",
    "def character_to_encoding(char, classes=classes):\n",
    "    for i in class_numerals:\n",
    "        if class_numerals[i] == char:\n",
    "            return np_utils.to_categorical(i, classes)\n",
    "\n",
    "def encoding_to_character(encoding):\n",
    "    return class_numerals[encoding.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: ['/job:localhost/replica:0/task:0/device:GPU:0']\n",
      "classes: 36\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    " \n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    " \n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "print(\"GPUs:\", k.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "# print(\"input shape:\", input_shape)\n",
    "print(\"classes:\", classes)\n",
    "\n",
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return gbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_count</th>\n",
       "      <th>Label#1</th>\n",
       "      <th>Label#2</th>\n",
       "      <th>Label#3</th>\n",
       "      <th>Label#4</th>\n",
       "      <th>Label#5</th>\n",
       "      <th>Label#6</th>\n",
       "      <th>Label#7</th>\n",
       "      <th>Label#8</th>\n",
       "      <th>Label#9</th>\n",
       "      <th>...</th>\n",
       "      <th>Label#29</th>\n",
       "      <th>Label#30</th>\n",
       "      <th>Label#31</th>\n",
       "      <th>Label#32</th>\n",
       "      <th>Label#33</th>\n",
       "      <th>Label#34</th>\n",
       "      <th>Label#35</th>\n",
       "      <th>Label#36</th>\n",
       "      <th>Test_acc</th>\n",
       "      <th>Overall_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Label_count, Label#1, Label#2, Label#3, Label#4, Label#5, Label#6, Label#7, Label#8, Label#9, Label#10, Label#11, Label#12, Label#13, Label#14, Label#15, Label#16, Label#17, Label#18, Label#19, Label#20, Label#21, Label#22, Label#23, Label#24, Label#25, Label#26, Label#27, Label#28, Label#29, Label#30, Label#31, Label#32, Label#33, Label#34, Label#35, Label#36, Test_acc, Overall_acc]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 ['ब', 'य', 'ञ', 'त', 'क्ष', 'फ', 'ठ', 'स', 'छ', 'ज्ञ', 'च', 'ण', 'द', 'र', 'ट', 'म', 'प', 'क', 'ङ', 'भ', 'न', 'ल', 'ह', 'त्र', 'ज', 'ख', 'झ', 'थ', 'घ', 'श', 'ष', 'ग', 'व', 'ढ', 'ड', 'ध']\n",
      "(72000, 32, 32, 1) (72000, 36)\n",
      "(57600, 32, 32, 1) (57600, 36) (14400, 32, 32, 1) (14400, 36)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_61 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 10, 10, 12)        1812      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 5, 5, 12)          0         \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 5, 5, 12)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 1, 1, 120)         36120     \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 512)               61952     \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 36)                18468     \n",
      "=================================================================\n",
      "Total params: 118,508\n",
      "Trainable params: 118,508\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "############################\n",
      "## Memory usage: 0.061 GB ##\n",
      "############################\n",
      "\n",
      "Train on 48960 samples, validate on 8640 samples\n",
      "Epoch 1/500\n",
      "48960/48960 [==============================] - 10s 200us/step - loss: 0.2365 - acc: 0.9487 - val_loss: 0.2539 - val_acc: 0.9475\n",
      "Epoch 2/500\n",
      "48960/48960 [==============================] - 6s 130us/step - loss: 0.2290 - acc: 0.9519 - val_loss: 0.2592 - val_acc: 0.9480\n",
      "Epoch 3/500\n",
      "48960/48960 [==============================] - 6s 130us/step - loss: 0.2349 - acc: 0.9507 - val_loss: 0.2544 - val_acc: 0.9479\n",
      "Epoch 4/500\n",
      "48960/48960 [==============================] - 6s 132us/step - loss: 0.2302 - acc: 0.9519 - val_loss: 0.2485 - val_acc: 0.9486\n",
      "Epoch 5/500\n",
      "48960/48960 [==============================] - 6s 132us/step - loss: 0.2278 - acc: 0.9527 - val_loss: 0.2435 - val_acc: 0.9514\n",
      "Epoch 6/500\n",
      "48960/48960 [==============================] - 6s 131us/step - loss: 0.2266 - acc: 0.9526 - val_loss: 0.2480 - val_acc: 0.9495\n",
      "Epoch 7/500\n",
      "48960/48960 [==============================] - 6s 132us/step - loss: 0.2237 - acc: 0.9528 - val_loss: 0.2485 - val_acc: 0.9510\n",
      "Epoch 8/500\n",
      "48960/48960 [==============================] - 7s 134us/step - loss: 0.2201 - acc: 0.9549 - val_loss: 0.2485 - val_acc: 0.9478\n",
      "Epoch 9/500\n",
      "48960/48960 [==============================] - 7s 135us/step - loss: 0.2265 - acc: 0.9522 - val_loss: 0.2712 - val_acc: 0.9436\n",
      "Epoch 10/500\n",
      "48960/48960 [==============================] - 7s 141us/step - loss: 0.2194 - acc: 0.9542 - val_loss: 0.2575 - val_acc: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_count</th>\n",
       "      <th>Label#1</th>\n",
       "      <th>Label#2</th>\n",
       "      <th>Label#3</th>\n",
       "      <th>Label#4</th>\n",
       "      <th>Label#5</th>\n",
       "      <th>Label#6</th>\n",
       "      <th>Label#7</th>\n",
       "      <th>Label#8</th>\n",
       "      <th>Label#9</th>\n",
       "      <th>...</th>\n",
       "      <th>Label#29</th>\n",
       "      <th>Label#30</th>\n",
       "      <th>Label#31</th>\n",
       "      <th>Label#32</th>\n",
       "      <th>Label#33</th>\n",
       "      <th>Label#34</th>\n",
       "      <th>Label#35</th>\n",
       "      <th>Label#36</th>\n",
       "      <th>Test_acc</th>\n",
       "      <th>Overall_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>ब</td>\n",
       "      <td>य</td>\n",
       "      <td>ञ</td>\n",
       "      <td>त</td>\n",
       "      <td>क्ष</td>\n",
       "      <td>फ</td>\n",
       "      <td>ठ</td>\n",
       "      <td>स</td>\n",
       "      <td>छ</td>\n",
       "      <td>...</td>\n",
       "      <td>घ</td>\n",
       "      <td>श</td>\n",
       "      <td>ष</td>\n",
       "      <td>ग</td>\n",
       "      <td>व</td>\n",
       "      <td>ढ</td>\n",
       "      <td>ड</td>\n",
       "      <td>ध</td>\n",
       "      <td>0.952569</td>\n",
       "      <td>0.974889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label_count Label#1 Label#2 Label#3 Label#4 Label#5 Label#6 Label#7  \\\n",
       "36          36       ब       य       ञ       त     क्ष       फ       ठ   \n",
       "\n",
       "   Label#8 Label#9     ...     Label#29 Label#30 Label#31 Label#32 Label#33  \\\n",
       "36       स       छ     ...            घ        श        ष        ग        व   \n",
       "\n",
       "   Label#34 Label#35 Label#36  Test_acc Overall_acc  \n",
       "36        ढ        ड        ध  0.952569    0.974889  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 9.38 s, total: 1min 32s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = classes\n",
    "epochs = 500\n",
    "k_r = 0.01\n",
    "b_r = 0.01\n",
    "dropout = 0.1\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "input_shape=(32, 32, 1)\n",
    "results = pd.DataFrame(columns=['Label_count']+[\"Label#\" + str(i) for i in range(1, classes+1)]+[\"Test_acc\", \"Overall_acc\"])\n",
    "display_dataframe(results)\n",
    "\n",
    "for number_of_characters_at_once in range(36, 37):\n",
    "    random_iterations = 1\n",
    "    for iteration in range(random_iterations):\n",
    "        #selecting labels\n",
    "        labels = list(data.keys())\n",
    "        np.random.shuffle(labels)\n",
    "        labels = labels[:number_of_characters_at_once]\n",
    "        print(\"\\n\", iteration, labels)\n",
    "        \n",
    "        #preparing relevant data\n",
    "        X = []\n",
    "        y = []\n",
    "        for ch in labels:\n",
    "            X += data[ch]\n",
    "            y += [ch] * len(data[ch])\n",
    "\n",
    "        #resizing input image and preprocessin\n",
    "        X = np.array(list(map(lambda x: cv2.resize(x/255, (input_shape[0], input_shape[1])).reshape((input_shape[0], input_shape[1], 1)), X)))\n",
    "        y_ = np.array(list(map(lambda x: character_to_encoding(x, classes), y)))\n",
    "        print(X.shape, y_.shape)\n",
    "\n",
    "        #train test split\n",
    "        train_ratio = 0.8\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_, train_size=0.8, random_state=20, shuffle=True, stratify=y)\n",
    "        print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "        \n",
    "        \n",
    "        #the model itself\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(6, kernel_size=(5, 5),\n",
    "                         activation='relu',\n",
    "        #                   kernel_initializer='he_normal',\n",
    "        #                   kernel_regularizer=keras.regularizers.l2(k_r),\n",
    "        #                   bias_regularizer=keras.regularizers.l2(b_r),\n",
    "                         input_shape=input_shape))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Conv2D(12, kernel_size=(5, 5),\n",
    "                         activation='relu',\n",
    "        #                   kernel_initializer='he_normal',\n",
    "        #                   kernel_regularizer=keras.regularizers.l2(k_r),\n",
    "        #                   bias_regularizer=keras.regularizers.l2(b_r)\n",
    "                        ))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Conv2D(120, kernel_size=(5, 5),\n",
    "                         activation='relu',\n",
    "        #                   kernel_initializer='he_normal',\n",
    "        #                   kernel_regularizer=keras.regularizers.l2(k_r),\n",
    "        #                   bias_regularizer=keras.regularizers.l2(b_r)\n",
    "                        ))\n",
    "\n",
    "        # NN\n",
    "        model.add(Flatten())\n",
    "        #hidden layer 1\n",
    "        model.add(Dense(512, activation='relu', kernel_initializer='he_normal',\n",
    "                        kernel_regularizer=keras.regularizers.l2(k_r)))\n",
    "        model.add(Dropout(dropout))\n",
    "        #output laye1\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        print(\"\\n############################\")\n",
    "        print(\"## Memory usage:\", get_model_memory_usage(batch_size=batch_size, model=model), \"GB ##\")\n",
    "        print(\"############################\\n\")\n",
    "\n",
    "        #adding custom weights\n",
    "        model.set_weights(keras.models.load_model(os.path.join(pickle_folder, \"lenet_relu_3_conv_layer.h5\")).get_weights())\n",
    "        \n",
    "        #run model\n",
    "        model.fit(X_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=1,\n",
    "                  validation_split=0.15,\n",
    "                callbacks = [early_stopping_callback])\n",
    "\n",
    "        #save model\n",
    "        filename = \"Lenet_\" + \"_\".join(labels) + '.h5'\n",
    "        try:\n",
    "            save_model(model, os.path.join(pickle_folder, filename))\n",
    "        except Exception as e:\n",
    "            os.remove(os.path.join(pickle_folder, filename))\n",
    "            save_model(model, os.path.join(pickle_folder, filename))\n",
    "            print(e)\n",
    "        \n",
    "        #update results\n",
    "        results.loc[number_of_characters_at_once*random_iterations + iteration] = [len(labels)] + labels + ['']*(classes-len(labels)) + [model.evaluate(X_test, y_test, verbose=0)[1], model.evaluate(X, y_, verbose=0)[1]]        \n",
    "        display_dataframe(results.tail(5))\n",
    "        results.to_csv(os.path.join(pickle_folder,'results_'+str(iteration) + '.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
