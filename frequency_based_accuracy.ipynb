{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "import keras\n",
    "from IPython.display import display as display_dataframe\n",
    "# from keras.applications.xception import Xception\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.applications.vgg19 import VGG19\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.mobilenetv2 import MobileNetV2\n",
    "# from keras.applications.densenet import DenseNet121\n",
    "import cv2\n",
    "import os\n",
    "import seaborn as sns\n",
    "# from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def display_all_in_a_list(image_list, titles=None, scale_factor=1):\n",
    "    '''\n",
    "    image_list: a single image, or a list of images\n",
    "    -----------------------------------\n",
    "    uses matplotlib to display all images in 'image_list' in the same cell\n",
    "    '''\n",
    "    plt.rcParams['figure.figsize'] = [10*scale_factor, len(image_list)*5*scale_factor]\n",
    "    _, axes = plt.subplots(len(image_list), 1)\n",
    "    if len(image_list) == 1:\n",
    "        axes.imshow(image_list[0])\n",
    "        if titles is not None:\n",
    "            axes.set_title(titles[0])\n",
    "    else:\n",
    "        for index in range(len(image_list)):\n",
    "            axes[index].imshow(image_list[index])\n",
    "            if titles is not None:\n",
    "                axes[index].set_title(titles[index])\n",
    "    plt.show()\n",
    "    \n",
    "def get_single_image(something, margin = 1):\n",
    "    #check for correct input shape\n",
    "    if len(something.shape) > 3:\n",
    "        raise Exception(\"Input should be of format (x, y, channels). Got {}\".format(something.shape))\n",
    "    \n",
    "    #calculate the output shape of our returned image\n",
    "    channels = something.shape[2]\n",
    "    rows = int(channels**0.5)\n",
    "    columns = int(channels / rows)\n",
    "    while channels % rows != 0:\n",
    "        rows -= 1\n",
    "    while channels % columns != 0:\n",
    "        columns += 1\n",
    "    print(\"{} rows and {} columns of shape {}.\".format(rows, columns, something.shape[:2]))\n",
    "    \n",
    "    margin = margin\n",
    "    value = 255\n",
    "        \n",
    "    # stack the columns\n",
    "    listy = [something[:, :, i*columns] for i in range(rows)]\n",
    "    for i in range(rows):\n",
    "        for j in range(1, columns):\n",
    "            if margin:\n",
    "                listy[i] = np.append(listy[i], np.array([[value]*margin]*listy[i].shape[0]), axis=1)\n",
    "            listy[i] = np.append(listy[i], something[:, :, i*columns + j], axis=1)\n",
    "    \n",
    "    #stack the rows\n",
    "    image = listy[0]\n",
    "    for i in range(1, rows):\n",
    "        if margin:\n",
    "            image = np.append(image, np.array([[value]*listy[i].shape[1]]*margin), axis=0)\n",
    "        image = np.append(image, listy[i], axis=0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data of format:\n",
      "data_length(श) = 2000\n",
      "data_length(ण) = 2000\n",
      "data_length(त्र) = 2000\n",
      "data_length(ञ) = 2000\n",
      "data_length(न) = 2000\n",
      "data_length(ह) = 2000\n",
      "data_length(भ) = 2000\n",
      "data_length(प) = 2000\n",
      "data_length(फ) = 2000\n",
      "data_length(ख) = 2000\n",
      "data_length(ङ) = 2000\n",
      "data_length(द) = 2000\n",
      "data_length(स) = 2000\n",
      "data_length(ग) = 2000\n",
      "data_length(क) = 2000\n",
      "data_length(थ) = 2000\n",
      "data_length(ल) = 2000\n",
      "data_length(ढ) = 2000\n",
      "data_length(घ) = 2000\n",
      "data_length(च) = 2000\n",
      "data_length(व) = 2000\n",
      "data_length(ड) = 2000\n",
      "data_length(म) = 2000\n",
      "data_length(झ) = 2000\n",
      "data_length(ज) = 2000\n",
      "data_length(य) = 2000\n",
      "data_length(ट) = 2000\n",
      "data_length(ध) = 2000\n",
      "data_length(ब) = 2000\n",
      "data_length(त) = 2000\n",
      "data_length(क्ष) = 2000\n",
      "data_length(ठ) = 2000\n",
      "data_length(ष) = 2000\n",
      "data_length(छ) = 2000\n",
      "data_length(ज्ञ) = 2000\n",
      "data_length(र) = 2000\n"
     ]
    }
   ],
   "source": [
    "#vgg can't take input of 28x28 so we shall resize all our images\n",
    "pickle_folder = \"pickle files\"\n",
    "input_shape=(32, 32, 1)\n",
    "data = pickle.load(open('data.pickle', 'rb'))\n",
    "print(\"Data of format:\")\n",
    "for ch in data:\n",
    "    print(\"data_length(\" + ch + \") =\", len(data[ch]))\n",
    "\n",
    "#no. of classes\n",
    "classes = len(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rearranging data in input-output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpickled\n"
     ]
    }
   ],
   "source": [
    "file = \"class_numerals_{}.pickle\".format(classes)\n",
    "if file in os.listdir(pickle_folder):\n",
    "    class_numerals = pickle.load(open(os.path.join(pickle_folder, file), 'rb'))\n",
    "    print(\"Unpickled\")\n",
    "else:\n",
    "    class_numerals = {i:list(data.keys())[i] for i in range(classes)}\n",
    "    pickle.dump(class_numerals, open(os.path.join(pickle_folder, file), 'wb'))\n",
    "    print(\"Error. Incompatible. Pickled new file:\", file)\n",
    "def character_to_encoding(char, classes=classes):\n",
    "    for i in class_numerals:\n",
    "        if class_numerals[i] == char:\n",
    "            return np_utils.to_categorical(i, classes)\n",
    "\n",
    "def encoding_to_character(encoding):\n",
    "    return class_numerals[encoding.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72000, 32, 32, 1) (72000, 36)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for ch in data:\n",
    "    X += data[ch]\n",
    "    y += [ch] * len(data[ch])\n",
    "    \n",
    "#resizing input image and preprocessin\n",
    "X = np.array(list(map(lambda x: cv2.resize(x/255, (input_shape[0], input_shape[1])).reshape((input_shape[0], input_shape[1], 1)), X)))\n",
    "y_ = np.array(list(map(lambda x: character_to_encoding(x, classes), y)))\n",
    "\n",
    "print(X.shape, y_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57600, 32, 32, 1), (57600, 36), (14400, 32, 32, 1), (14400, 36))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_, train_size=0.8, random_state=20, shuffle=True, stratify=y)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: []\n",
      "input shape: (32, 32, 1)\n",
      "classes: 36\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    " \n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    " \n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "print(\"GPUs:\", k.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "print(\"input shape:\", input_shape)\n",
    "print(\"classes:\", classes)\n",
    "\n",
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return gbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"pickle files/36/Lenet_ब_य_ञ_त_क्ष_फ_ठ_स_छ_ज्ञ_च_ण_द_र_ट_म_प_क_ङ_भ_न_ल_ह_त्र_ज_ख_झ_थ_घ_श_ष_ग_व_ढ_ड_ध.h5\"\n",
    "model = keras.models.load_model(os.path.join(path_to_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test = X_test, y_test\n",
    "# temp_test = X_train, y_train\n",
    "a = model.predict_classes(temp_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400,) (14400,)\n",
      "(683,) (683,) (683, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "g = lambda n: [0]*n + [1] + [0]*(35-n)\n",
    "X_test, y_test = temp_test\n",
    "y_pred = np.array(list(map(g, a)))\n",
    "y_pred = np.array(list(map(encoding_to_character, y_pred)))\n",
    "y_test = np.array(list(map(encoding_to_character, y_test)))\n",
    "print(y_test.shape, y_pred.shape)\n",
    "\n",
    "falsify = ~(y_test == y_pred)\n",
    "y_pred = y_pred[falsify]\n",
    "y_test = y_test[falsify]\n",
    "X_test = X_test[falsify]\n",
    "X_test = X_test.reshape(X_test.shape[:-1])\n",
    "print(y_test.shape, y_pred.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_character_accuracy = {i: 0 for i in data.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for character in np.unique(y_test):\n",
    "    per_character_accuracy[character] = 1-sum(y_test == character)/400\n",
    "#     wrongly_predicted = pd.Series(y_pred[y_test == character]).value_counts().argmax()\n",
    "#     display_dataframe(pd.DataFrame(pd.Series(y_pred[y_test == character]).value_counts()).transpose())\n",
    "#     display_all_in_a_list(X_test[(y_test==character) & (y_pred==wrongly_predicted)])\n",
    "#     print(\"\\n\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_frequency = {'क': 4468,\n",
    " 'क्ष': 125,\n",
    " 'ख': 341,\n",
    " 'ग': 679,\n",
    " 'घ': 122,\n",
    " 'ङ': 0,\n",
    " 'च': 661,\n",
    " 'छ': 194,\n",
    " 'ज': 848,\n",
    " 'ज्ञ': 25,\n",
    " 'झ': 117,\n",
    " 'ञ': 3,\n",
    " 'ट': 294,\n",
    " 'ठ': 128,\n",
    " 'ड': 270,\n",
    " 'ढ': 92,\n",
    " 'ण': 316,\n",
    " 'त': 3120,\n",
    " 'त्र': 143,\n",
    " 'थ': 543,\n",
    " 'द': 1260,\n",
    " 'ध': 490,\n",
    " 'न': 3236,\n",
    " 'प': 1858,\n",
    " 'फ': 84,\n",
    " 'ब': 716,\n",
    " 'भ': 805,\n",
    " 'म': 1921,\n",
    " 'य': 1553,\n",
    " 'र': 4116,\n",
    " 'ल': 1128,\n",
    " 'व': 1850,\n",
    " 'श': 589,\n",
    " 'ष': 361,\n",
    " 'स': 2645,\n",
    " 'ह': 3178}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38279 0.9622790564016824\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "total_characters = 0\n",
    "for ch in per_character_accuracy:\n",
    "    accuracy += per_character_accuracy[ch] * character_frequency[ch]\n",
    "    total_characters += character_frequency[ch]\n",
    "    \n",
    "print(total_characters, accuracy/total_characters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
